# Deep Reinforcement Learning for Multi-Agent Systems on the Example of Chess 
---
Author: Helen Haase

Supervisor: Prof. Dr. Thomas Clemen

---
## Project Overview 
Cooperative multi-agent learning represents a formidable challenge within the realm of artificial intelligence research. This challenge becomes particularly evident in scenarios with high-dimensional environments where agents possess diverse capabilities and must adhere to specific rules while collaboratively learning from experts. Imitation learning emerges as a promising solution, allowing agents to acquire policies through the study of expert demonstrations in the absence of direct reward signals. 

This project aims to train a heterogenous group of agents to learn their individual action spaces as well as a starting behavior to cooperatively learn to together. The example of chess is chosen, as the action spaces varies and even agents with the same action space may behave differently depending on their position in the game and therefore the primary goal. The chess game is modelled using markov games. 

The following poster gives a short overview of the different steps. It is to say that before the group-decision making is being modelled, the individual agents have to be trained, which is the focus in this project. The idea relates to real world problems, where for example multiple robots cooperatively manufacture a product. Instead of teaching each robot very specific which actions it can perform and in which sequence the tasks should be executed by the different agents, it would simplify the process, if agents learned their capabilities themselves and also collaboratively decide which tasks is performed when and by whom. 

![DRL for MAS](readme_figs/Helen_Haase_FW2_Poster.png)

## Usage of the repository
In the project folder you find a README, specifying how to setup the project. It also explains the different folders and files. If you already set everything up, 
you can proceed learning about the content by reading through the  `example_notebook.ipynb`  in project/src. Afterwards it should be easier to change experiment setups and add new extensions.

    
    ðŸ“¦project
    â”£ ðŸ“‚dataset
    â”ƒ â”£ ðŸ“œ03_sorted_100.txt
    â”ƒ â”£ ðŸ“œ03_sorted_1000.txt
    â”ƒ â”£ ðŸ“œ03_sorted_5000.txt
    â”ƒ â”£ ðŸ“œ03_sorted_10000.txt
    â”— ðŸ“‚src
    â”ƒ â”£ ðŸ“œexample_notebook.ipynb
    â”ƒ â”£ ðŸ“œmain.py
    â”ƒ â”£ ðŸ“œconstants.py
    â”ƒ â”£ ðŸ“œDQN.py
    â”ƒ â”£ ðŸ“œplotting.py
    â”ƒ â”£ ðŸ“œObservationSpaceModeller.py
    â”ƒ â”£ ðŸ“œ... 
    ðŸ“¦poster
    â”£ ðŸ“œHelen_Haase_FW2_Poster.pdf
    â”— ðŸ“œ...
  
